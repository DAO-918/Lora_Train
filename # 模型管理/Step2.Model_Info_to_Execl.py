"""
ä»¥ä¸‹æ˜¯éƒ¨åˆ†jsonæ–‡ä»¶çš„å†…å®¹ï¼Œè®°å½•äº†æ‰€æœ‰æ¨¡å‹çš„ä¿¡æ¯ï¼š
{
  "Lora\\SD_XL_è§’è‰²\\25D_XL_è§’è‰²_marie rose.safetensors": {
    "name": "25D_XL_è§’è‰²_marie rose",
    "type": "",
    "url": "https://civitai.com/models/128594?modelVersionId=385001",
    "description": "=== ä»CivitaiæŠ“å–çš„æè¿° ===\nI've trained two sets of clothing. The trigger words are as follows\n\ntype A: pantyhose, sweater, jacket\n\ntype B: shirt, skirt, fishnet thighhighs\n\n\nV3.0\n\nThe previous 1.0 version of Marie was really too ugly, so I collected a large amount of new material and made the latest XL version, which took a lot of time... I hope everyone can provide more image feedback to build the SDXL community ecosystem and let more people know the advantages of XL...\n\n\nç°åœ¨ç½‘ä¸Šçš„aiç›ä¸½å®åœ¨æ˜¯å¤ªä¸‘äº†ä¸å¿ç›´è§†ï¼Œå› æ­¤å¸Œæœ›å¤§å®¶ç”¨è¿™ä¸ªæ¨¡å‹åˆ›é€ å‡ºæ›´å¤šå¯çˆ±çš„è¿˜åŸçš„ç›ä¸½ï¼Œæ›´å¤šçš„ä¼˜è´¨è¿”å›¾å°±æ˜¯å¯¹æˆ‘æœ€å¤§çš„æ”¯æŒï¼Œä¹Ÿå¸Œæœ›å’Œæ›´å¤šçš„æœ‹å‹è®¨è®ºå¦‚ä½•ç”Ÿæˆæ›´å¥½çœ‹çš„ç›ä¸½ã€‚å¯ä»¥å…³æ³¨æˆ‘çš„pç«™å’ŒXè´¦å·ï¼Œä»¥åä¼šæœ‰æ›´å¤šçš„å›¾ç‰‡åˆ›ä½œä»¥åŠä¼˜è´¨æ¨¡å‹æ”¾å‡º...",
    "trigger_words": "marie rose",
    "hash": "bdfcc89aa58d85c7909b4b85f813b50797cc3c0a9120ab8b17a40c18d4bfee01",
    "is_favorite": false,
    "last_modified": 1734931371.922711
  },
pythonï¼Œå…¨ç¨‹ä½¿ç”¨openpyxl
ç¬¬ä¸€å±‚é”®ååŠ ä¸Šfolder_pathå°±æ˜¯æ–‡ä»¶çš„å­˜å‚¨è·¯å¾„,è¯¥è·¯å¾„ä¸‹æœ‰åŒåçš„npgæ–‡ä»¶å’Œå…³äºè¯¥æ¨¡å‹çš„jsonä¿¡æ¯ï¼Œç¤ºä¾‹å¦‚ä¸‹ï¼š
{
    "description": "description",
    "sd version": "Flux",
    "activation text": "marie rose",
    "preferred weight": 0.76,
    "negative text": "Negative prompt\n",
    "notes": "Notes"
}
ç¬¬äºŒå±‚é”®ååŒ…æ‹¬äº†ï¼šname,type,url,description,trigger_words,hash,is_favorite,last_modified

ç°åœ¨è¦æ±‚å°†jsonçš„ä¿¡æ¯è½¬æ¢æˆexeclçš„æ ¼å¼
"Lora\\SD_XL_è§’è‰²\\25D_XL_è§’è‰²_marie rose.safetensors"ï¼Œ"Lora"æ˜¯å†™å…¥sheetçš„åç§°ï¼Œ"SD_XL_è§’è‰²"æ˜¯æ¨¡å‹çš„æ–‡ä»¶å¤¹åï¼Œ"25D_XL_è§’è‰²_marie rose"æ˜¯æ¨¡å‹çš„æ–‡ä»¶åï¼Œsafetensorsæ˜¯æ–‡ä»¶çš„åç¼€å
åŒæ—¶è¦è·å–è¯¥æ¨¡å‹è·¯å¾„ä¸‹çš„åŒåçš„npgæ–‡ä»¶è·¯å¾„å’ŒåŒåçš„jsonæ–‡ä»¶(å…³äºè¯¥æ¨¡å‹çš„jsonä¿¡æ¯)ï¼Œè¦åˆ¤æ–­æ˜¯å¦å­˜åœ¨png,æ²¡æœ‰åˆ™ä¸å†™å…¥img_pathå’Œæ’å…¥å›¾ç‰‡ï¼›è¦åˆ¤æ–­æ˜¯å¦å­˜åœ¨pngï¼Œæ²¡æœ‰åˆ™preferred weight,negative text,notesä¸å†™å…¥
è¡¨æ ¼ä»Aåˆ—å¼€å§‹ä¾æ¬¡æ˜¯ï¼šname,æ–‡ä»¶å¤¹å,type,url,img_path,æ’å…¥å›¾ç‰‡,description,notes,trigger_words,preferred weight,negative text,hash,is_favorite,last_modified
"""

"""
headers = [
                "æ–‡ä»¶å", "åŸå", "æ–‡ä»¶å¤¹å", "ç±»å‹", "é£æ ¼", "ç”¨é€”", "ç‰ˆæœ¬", "url", "å›¾ç‰‡è·¯å¾„", "å›¾ç‰‡é¢„è§ˆ", 
                "æè¿°", "è§¦å‘è¯", "å¯é€‰ç»„åˆ", "notes", "é»˜è®¤æƒé‡", "æƒé‡èŒƒå›´", "å¦å®šæç¤ºè¯", 
                "hash","å–œçˆ±", "ä¿®æ”¹æ—¶é—´"
            ]
ä½¿ç”¨pythonå’Œopenpyxlï¼Œæˆ‘ä¼šä¿®æ”¹è¡¨æ ¼ä¸­çš„å†…å®¹ï¼Œæ–°çš„æ–‡ä»¶åæŒ‰ç…§ "ç±»å‹_ç”¨é€”_é£æ ¼_åŸå_ç‰ˆæœ¬" çš„æ ¼å¼ï¼Œå¦‚æœæœ‰ç©ºå€¼åˆ™ä¸å†™å…¥åˆ°æ–°æ–‡ä»¶åä¸­ã€‚
å¯¹æ¯”åŸæ–‡ä»¶å(å³è¡¨æ ¼ä¸­çš„æ–‡ä»¶å)ï¼Œå¦‚æœä¸ä¸€è‡´ï¼Œåˆ™ä¿®æ”¹æ¨¡å‹çš„æ–‡ä»¶åä»¥åŠå¯¹åº”å›¾ç‰‡æ–‡ä»¶åå’ŒJSONæ–‡ä»¶åï¼Œå¦‚æœä¸€è‡´ï¼Œåˆ™ä¸ä¿®æ”¹ã€‚
ä¸‹é¢æ˜¯æˆ‘å†™çš„ä¸€éƒ¨åˆ†ä»£ç ï¼Œè¯·å¦å¤–å†™å‡ºä¸€ä¸ªæ£€æŸ¥å¹¶ä¿®æ”¹æ–‡ä»¶åçš„æ–¹æ³•ã€‚
"""

"""
model_info.josnçš„éƒ¨åˆ†å†…å®¹ï¼š
{
  "Lora\\SD_XL_è§’è‰²\\25D_XL_è§’è‰²_marie rose.safetensors": {
    "name": "25D_XL_è§’è‰²_marie rose",
    "type": "",
    "url": "https://civitai.com/models/128594?modelVersionId=385001",
    "description": "=== ä»CivitaiæŠ“å–çš„æè¿° ===\nI've trained two sets of clothing. The trigger words are as follows\n\ntype A: pantyhose, sweater, jacket\n\ntype B: shirt, skirt, fishnet thighhighs\n\n\nV3.0\n\nThe previous 1.0 version of Marie was really too ugly, so I collected a large amount of new material and made the latest XL version, which took a lot of time... I hope everyone can provide more image feedback to build the SDXL community ecosystem and let more people know the advantages of XL...\n\n\nç°åœ¨ç½‘ä¸Šçš„aiç›ä¸½å®åœ¨æ˜¯å¤ªä¸‘äº†ä¸å¿ç›´è§†ï¼Œå› æ­¤å¸Œæœ›å¤§å®¶ç”¨è¿™ä¸ªæ¨¡å‹åˆ›é€ å‡ºæ›´å¤šå¯çˆ±çš„è¿˜åŸçš„ç›ä¸½ï¼Œæ›´å¤šçš„ä¼˜è´¨è¿”å›¾å°±æ˜¯å¯¹æˆ‘æœ€å¤§çš„æ”¯æŒï¼Œä¹Ÿå¸Œæœ›å’Œæ›´å¤šçš„æœ‹å‹è®¨è®ºå¦‚ä½•ç”Ÿæˆæ›´å¥½çœ‹çš„ç›ä¸½ã€‚å¯ä»¥å…³æ³¨æˆ‘çš„pç«™å’ŒXè´¦å·ï¼Œä»¥åä¼šæœ‰æ›´å¤šçš„å›¾ç‰‡åˆ›ä½œä»¥åŠä¼˜è´¨æ¨¡å‹æ”¾å‡º...",
    "trigger_words": "marie rose",
    "hash": "bdfcc89aa58d85c7909b4b85f813b50797cc3c0a9120ab8b17a40c18d4bfee01",
    "is_favorite": false,
    "last_modified": 1734931371.922711
  },

headers = [
                "æ–‡ä»¶å", "åŸå", "æ–‡ä»¶å¤¹å", "ç±»å‹", "é£æ ¼", "ç”¨é€”", "ç‰ˆæœ¬", "url", "å›¾ç‰‡è·¯å¾„", "å›¾ç‰‡é¢„è§ˆ", 
                "æè¿°", "è§¦å‘è¯", "å¯é€‰ç»„åˆ", "notes", "é»˜è®¤æƒé‡", "æƒé‡èŒƒå›´", "å¦å®šæç¤ºè¯", 
                "hash","å–œçˆ±", "ä¿®æ”¹æ—¶é—´"
            ]
å°†excelçš„æ•°æ®é‡æ–°å†™åˆ°model_info.jsonå’Œæ¨¡å‹å¯¹åº”åŒåçš„jsonæ–‡ä»¶ä¸­ã€‚
å…¶ä¸­model_info.jsonçš„é”®åæ˜¯å·¥ä½œè¡¨sheetåç§°+æ–‡ä»¶å+æ–‡ä»¶åï¼Œéœ€è¦å†™å…¥çš„è¡¨æ ¼ä¸­åŒ…å«çš„æ‰€æœ‰æ•°æ®ï¼Œé™¤äº†åŸæ¥model_info.jsonæœ‰çš„å€¼ï¼Œå…¶ä»–çš„é”®åæŒ‰è¡¨æ ¼ä¸­çš„åˆ—åå‘½å


æ¨¡å‹å¯¹åº”åŒåçš„jsonæ–‡ä»¶çš„ç¤ºä¾‹å¦‚ä¸‹ï¼š
{
    "description": "=== ä»CivitaiæŠ“å–çš„æè¿° ===\nI've trained two sets of clothing. The trigger words are as follows\n\ntype A: pantyhose, sweater, jacket\n\ntype B: shirt, skirt, fishnet thighhighs\n\n\nV3.0\n\nThe previous 1.0 version of Marie was really too ugly, so I collected a large amount of new material and made the latest XL version, which took a lot of time... I hope everyone can provide more image feedback to build the SDXL community ecosystem and let more people know the advantages of XL...\n\n\nç°åœ¨ç½‘ä¸Šçš„aiç›ä¸½å®åœ¨æ˜¯å¤ªä¸‘äº†ä¸å¿ç›´è§†ï¼Œå› æ­¤å¸Œæœ›å¤§å®¶ç”¨è¿™ä¸ªæ¨¡å‹åˆ›é€ å‡ºæ›´å¤šå¯çˆ±çš„è¿˜åŸçš„ç›ä¸½ï¼Œæ›´å¤šçš„ä¼˜è´¨è¿”å›¾å°±æ˜¯å¯¹æˆ‘æœ€å¤§çš„æ”¯æŒï¼Œä¹Ÿå¸Œæœ›å’Œæ›´å¤šçš„æœ‹å‹è®¨è®ºå¦‚ä½•ç”Ÿæˆæ›´å¥½çœ‹çš„ç›ä¸½ã€‚å¯ä»¥å…³æ³¨æˆ‘çš„pç«™å’ŒXè´¦å·ï¼Œä»¥åä¼šæœ‰æ›´å¤šçš„å›¾ç‰‡åˆ›ä½œä»¥åŠä¼˜è´¨æ¨¡å‹æ”¾å‡º...",
    "sd version": "Flux",
    "activation text": "marie rose",
    "preferred weight": 0.76,
    "negative text": "Negative prompt\n",
    "notes": "Notes"
}
ä¹Ÿä¸€æ ·å†™å…¥çš„è¡¨æ ¼ä¸­åŒ…å«çš„æ‰€æœ‰æ•°æ®ï¼Œé™¤äº†åŸæ¥æœ‰çš„å€¼ï¼Œå…¶ä»–çš„é”®åæŒ‰è¡¨æ ¼ä¸­çš„åˆ—åå‘½å

ä¸‹é¢æ˜¯æˆ‘å†™çš„éƒ¨åˆ†ä»£ç ï¼Œä»…ä¾›å‚è€ƒï¼Œå¦å¤–å†™ä¸€ä¸ªæ–¹æ³•å®Œæˆæˆ‘ä¸Šé¢æåˆ°çš„è¦æ±‚ï¼š
"""

"""
æ¨¡ä»¿ä»¥ä¸‹ä»£ç é£æ ¼ï¼Œä¸éœ€è¦è€ƒè™‘ä»£ç æ•ˆç‡ä¼˜åŒ–ï¼Œä¿æŒç®€å•æ˜“æ‡‚
æ¨¡ä»¿ä»£ç å†™æ³•ï¼Œå¦å¤–å†™ä¸€ä¸ªæ–¹æ³•ï¼Œå½“æ–°æ–‡ä»¶å¤¹åˆ—ä¸­æœ‰å€¼æ—¶éœ€è¦å°†æ¨¡å‹ã€jsonæ–‡ä»¶å’Œå›¾ç‰‡éƒ½ç§»åŠ¨åˆ°æ–°æ–‡ä»¶å¤¹ä¸‹

"""

import logging
import sys
import io
import os
import time
import json
from openpyxl import load_workbook
from openpyxl.utils import get_column_letter
from openpyxl.styles import Alignment, Font
import openpyxl.utils
from openpyxl.drawing.image import Image as OpenpyxlImage
from PIL import Image as PILImage
from openpyxl.worksheet.hyperlink import Hyperlink
from openpyxl import Workbook


def json_to_execl(folder_path):
    json_name = "model_info.json"
    json_path = os.path.join(folder_path, json_name)
    with open(json_path, 'r', encoding='utf-8') as f:
        json_data = json.load(f)
    
    excel_name = "model_info.xlsx"
    excel_path = os.path.join(folder_path, excel_name)
    wb = load_workbook(excel_path)
    
    sheets = wb.sheetnames
    # å…ˆéå†æ‰€æœ‰å·¥ä½œè¡¨æ¸…ç©ºå·²æœ‰å›¾ç‰‡
    for sheet in sheets:
        ws = wb[sheet]
        # è·å–å›¾ç‰‡çš„åˆ—è¡¨
        images = list(ws._images)  # åˆ›å»ºä¸€ä¸ªå‰¯æœ¬ä»¥é¿å…åœ¨è¿­ä»£æ—¶ä¿®æ”¹åˆ—è¡¨é•¿åº¦
        for drawing in images:
            ws._images.remove(drawing)
    
    # åˆ é™¤é»˜è®¤ç”Ÿæˆçš„å·¥ä½œè¡¨ï¼ˆé€šå¸¸åä¸º'Sheet'ï¼‰
    default_sheet_name = 'Sheet'
    for sheet in wb.sheetnames:
        if default_sheet_name in sheet:
            default_sheet = wb[sheet]
            wb.remove(default_sheet)
    
    for file_path, model_info in json_data.items():
        # åˆ†è§£è·¯å¾„å’Œæ–‡ä»¶ä¿¡æ¯
        split_list = file_path.split('\\')
        if len(split_list) == 2:
            sheet_name = split_list[0]
            folder_name = ''
            file_name_ext = split_list[1]
        elif len(split_list) == 3:
            sheet_name = split_list[0]
            folder_name = split_list[1]
            file_name_ext = split_list[2]
        file_name, file_ext = os.path.splitext(file_name_ext)
        
        # è·å–ç›¸å…³è·¯å¾„  
        model_dir = os.path.join(folder_path,sheet_name)
        if bool(folder_name):
            model_dir = os.path.join(model_dir,folder_name)
        img_path = os.path.join(model_dir, file_name + '.png')
        model_json_path = os.path.join(model_dir, file_name + '.json')
        
        # åˆ¤æ–­æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        model_path = os.path.join(model_dir, file_name_ext)
        if not os.path.exists(model_path):
            continue
        
        # è¯»å–æ¨¡å‹ JSON ä¿¡æ¯
        model_extra_info = {}
        if os.path.exists(model_json_path):
            with open(model_json_path, 'r', encoding='utf-8') as f:
                model_extra_info = json.load(f)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        img_exists = os.path.exists(img_path)
        json_exists = os.path.exists(model_json_path)
        
        # å¦‚æœå·¥ä½œè¡¨ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»º
        if sheet_name not in wb.sheetnames:
            ws = wb.create_sheet(title=sheet_name)
            # å†™å…¥è¡¨å¤´
            headers = [
                "æ–‡ä»¶å", "æ‹“å±•å", "åŸå", "æ–‡ä»¶å¤¹å", "æ–°æ–‡ä»¶å¤¹", "ç±»å‹", "é£æ ¼", "ç”¨é€”", "ç‰ˆæœ¬", "url", "å›¾ç‰‡è·¯å¾„", "å›¾ç‰‡é¢„è§ˆ", 
                "æè¿°", "SD Link", "ç‰¹æŒ‡è¯", "ä¸»æè¿°è¯", "è§¦å‘è¯", "å¯é€‰å½¢è±¡", "å¯é€‰æœè£…", "notes", "é»˜è®¤æƒé‡", "æƒé‡èŒƒå›´", "å¦å®šæç¤ºè¯", 
                "hash","å–œçˆ±", "ä¿®æ”¹æ—¶é—´"
            ]
            ws.append(headers)
        else:
            ws = wb[sheet_name]
        
        # æ£€æŸ¥æ•°æ®æ˜¯å¦å­˜åœ¨
        file_name_exsit = False
        for row in ws.iter_rows(min_row=2):
            if row[0].value == file_name:
                file_name_exsit = True
                break
        if file_name_exsit:
            continue
        
        # å†™å…¥è¡Œæ•°æ®
        row_data = [
            file_name, #1 æ–‡ä»¶å
            file_ext,  #2 æ‹“å±•å
            model_info.get("pname", file_name), #3 åŸå å¦‚æœä¸è¿™æ ·å†™ç¬¬ä¸€æ¬¡å†™å…¥è¿™ä¸€è¡Œä¸ºç©ºï¼Œä¼šå½±å“åé¢ç¨‹åºçš„è¿è¡Œï¼Œåœ¨rename_filenamesä¸­æ—§æ–‡ä»¶åæ˜¯æœ‰å€¼çš„ï¼Œè€Œæ–°æ–‡ä»¶åæ˜¯ç©ºçš„ï¼Œå¯¼è‡´æ›´æ–°æ–‡ä»¶åç›´æ¥å˜æˆç©º
            folder_name, #4 æ–‡ä»¶å¤¹å
            "", #5 æ–°æ–‡ä»¶å¤¹
            model_info.get("type", ""), #6 ç±»å‹ ä¼šå†™å…¥æ¨¡å‹jsonçš„sd version
            model_info.get("é£æ ¼", ""), #7 é£æ ¼
            model_info.get("ç”¨é€”", ""), #8 ç”¨é€”
            model_info.get("ç‰ˆæœ¬", ""), #9 ç‰ˆæœ¬
            model_info.get("url", ""), #10 url
            img_path, #11 å›¾ç‰‡è·¯å¾„ ä¸åˆ¤æ–­å›¾ç‰‡æ˜¯å¦å­˜åœ¨  if img_exists else "" å¡«å……æ—¶å†åˆ¤æ–­
            "", #12 å›¾ç‰‡é¢„è§ˆ
            str(model_info.get("description", "")).replace('=', ''), #13 æè¿° ä¼šå†™å…¥æ¨¡å‹jsonçš„description
            model_info.get("SD Link", ""), # 14 SD Link
            model_info.get("specific_words", ""), # 15 ç‰¹æŒ‡è¯
            model_info.get("main_words", ""), #16 ä¸»æè¿°è¯
            model_info.get("trigger_words", ""), #17 è§¦å‘è¯ ä¼šå†™å…¥æ¨¡å‹jsonçš„activation text
            model_info.get("å¯é€‰å½¢è±¡", ""), #18 å¯é€‰å½¢è±¡
            model_info.get("å¯é€‰æœè£…", ""), #18 å¯é€‰æœè£…
            model_extra_info.get("notes", "") if json_exists else "", #19 notes ä¼šå†™å…¥æ¨¡å‹jsonçš„notes
            model_extra_info.get("preferred weight", "") if json_exists else "", #20 é»˜è®¤æƒé‡ ä¼šå†™å…¥æ¨¡å‹jsonçš„preferred weight
            model_info.get("æƒé‡èŒƒå›´", ""), #21 æƒé‡èŒƒå›´
            model_extra_info.get("negative text", "") if json_exists else "", #22 å¦å®šæç¤ºè¯ ä¼šå†™å…¥æ¨¡å‹jsonçš„negative text
            model_info.get("hash", ""), #23 hash
            model_info.get("is_favorite", ""), #24 å–œçˆ±
            model_info.get("last_modified", "") #25 ä¿®æ”¹æ—¶é—´
        ]
        ws.append(row_data)
    
    wb.save(excel_path)


def rename_filenames(folder_path):
    excel_name = "model_info.xlsx"
    excel_path = os.path.join(folder_path, excel_name)
    wb = load_workbook(excel_path)
    
    sheets = wb.sheetnames
    for sheet in sheets:
        ws = wb[sheet]
        
        # è·å–è¡¨å¤´ç´¢å¼•
        headers = [
                "æ–‡ä»¶å", "æ‹“å±•å", "åŸå", "æ–‡ä»¶å¤¹å", "æ–°æ–‡ä»¶å¤¹", "ç±»å‹", "é£æ ¼", "ç”¨é€”", "ç‰ˆæœ¬", "url", "å›¾ç‰‡è·¯å¾„", "å›¾ç‰‡é¢„è§ˆ", 
                "æè¿°", "SD Link", "ç‰¹æŒ‡è¯", "ä¸»æè¿°è¯", "è§¦å‘è¯", "å¯é€‰å½¢è±¡", "å¯é€‰æœè£…", "notes", "é»˜è®¤æƒé‡", "æƒé‡èŒƒå›´", "å¦å®šæç¤ºè¯", 
                "hash","å–œçˆ±", "ä¿®æ”¹æ—¶é—´"
            ]
        header_index = {header: idx for idx, header in enumerate(headers)}
        
        rows = list(ws.iter_rows(min_row=2, values_only=True))
        total_rows = len(rows)  
        columns = [cell.value for cell in list(ws.iter_rows(min_row=1, max_row=1))[0]]
        index_æ–‡ä»¶å = columns.index('æ–‡ä»¶å')+1
        index_æ‹“å±•å = columns.index('æ‹“å±•å')+1
        index_åŸå = columns.index('åŸå')+1
        index_æ–‡ä»¶å¤¹å = columns.index('æ–‡ä»¶å¤¹å')+1
        index_å›¾ç‰‡è·¯å¾„ = columns.index('å›¾ç‰‡è·¯å¾„')+1
        index_ç±»å‹ = columns.index('ç±»å‹')+1
        index_é£æ ¼ = columns.index('é£æ ¼')+1
        index_ç”¨é€” = columns.index('ç”¨é€”')+1
        index_ç‰ˆæœ¬ = columns.index('ç‰ˆæœ¬')+1
        
        for row in ws.iter_rows(min_row=2):
            # ç±»å‹_ç”¨é€”_é£æ ¼_åŸå_ç‰ˆæœ¬
            ç±»å‹ = row[index_ç±»å‹-1].value
            ç”¨é€” = row[index_ç”¨é€”-1].value
            é£æ ¼ = row[index_é£æ ¼-1].value
            åŸå = row[index_åŸå-1].value
            ç‰ˆæœ¬ = row[index_ç‰ˆæœ¬-1].value
            new_filename_parts = [ç±»å‹, ç”¨é€”, é£æ ¼, åŸå, ç‰ˆæœ¬]
            # bool æ˜¯ä¸€ä¸ªå†…ç½®å‡½æ•°ï¼Œå®ƒä¼šå°†æ¯ä¸ªå…ƒç´ è½¬æ¢æˆå¸ƒå°”å€¼ï¼ˆTrue æˆ– Falseï¼‰ã€‚
            # å¦‚æœå…ƒç´ æ˜¯ Noneã€ç©ºå­—ç¬¦ä¸² ""ã€æ•°å­— 0ã€ç©ºåˆ—è¡¨ç­‰å‡å€¼ï¼Œå®ƒä¼šè¿”å› Falseï¼Œå¦åˆ™è¿”å› True
            # å¦‚æœ new_filename_parts æ˜¯ ["ç±»å‹", "", "é£æ ¼", None, "ç‰ˆæœ¬"]ï¼Œé‚£ä¹ˆ filter(bool, new_filename_parts) ä¼šè¿”å› ["ç±»å‹", "é£æ ¼", "ç‰ˆæœ¬"]
            new_filename = "_".join(filter(bool, new_filename_parts))
            old_filename = row[index_æ–‡ä»¶å-1].value
            
            æ–‡ä»¶å¤¹å = row[index_æ–‡ä»¶å¤¹å-1].value
            if æ–‡ä»¶å¤¹å:
                file_folder = os.path.join(folder_path, sheet, æ–‡ä»¶å¤¹å)
            else:
                file_folder = os.path.join(folder_path, sheet)
                
            if not bool(old_filename) or not bool(new_filename):
                #print("è‡³å°‘æœ‰ä¸€ä¸ªè·¯å¾„æ˜¯å‡å€¼")
                continue
                
            if old_filename != new_filename:
                try:
                    æ‹“å±•å = row[index_æ‹“å±•å-1].value
                    old_model_path = os.path.join(file_folder, f'{old_filename}{æ‹“å±•å}')
                    new_model_path = os.path.join(file_folder, f'{new_filename}{æ‹“å±•å}')
                    #print(os.path.exists(old_model_path))
                    if os.path.exists(old_model_path):
                        os.rename(old_model_path, new_model_path)
                except Exception as e:
                    print(e)
                
                try:
                    å›¾ç‰‡è·¯å¾„ = row[index_å›¾ç‰‡è·¯å¾„-1].value
                    old_image_path = os.path.join(file_folder, f'{old_filename}.png')
                    new_image_path = os.path.join(file_folder, f'{new_filename}.png')
                    # å›¾ç‰‡è¦å­˜åœ¨æ‰èƒ½ä¿®æ”¹
                    if å›¾ç‰‡è·¯å¾„:
                        if os.path.exists(old_image_path):
                            os.rename(old_image_path, new_image_path)
                            row[index_å›¾ç‰‡è·¯å¾„-1].value = new_image_path
                except Exception as e:
                    print(e)
                
                try:
                    old_json_path = os.path.join(file_folder, f'{old_filename}.json')
                    new_json_path = os.path.join(file_folder, f'{new_filename}.json')
                    if os.path.exists(old_json_path):
                        os.rename(old_json_path, new_json_path)
                except Exception as e:
                    print(e)
                
                # å¯è¡Œçš„ï¼Œæœ¬è´¨ä¸Šæ˜¯cellæ•°æ®æ ¼å¼
                row[index_æ–‡ä»¶å-1].value = new_filename
    
    # ä¿å­˜ä¿®æ”¹åçš„è¡¨æ ¼
    wb.save(excel_path)

def move_to_newfolder(folder_path):
    excel_name = "model_info.xlsx"
    excel_path = os.path.join(folder_path, excel_name)
    wb = load_workbook(excel_path)
    
    sheets = wb.sheetnames
    for sheet in sheets:
        ws = wb[sheet]
        
        # è·å–è¡¨å¤´ç´¢å¼•
        columns = [cell.value for cell in list(ws.iter_rows(min_row=1, max_row=1))[0]]
        index_æ–‡ä»¶å = columns.index('æ–‡ä»¶å') + 1
        index_æ‹“å±•å = columns.index('æ‹“å±•å') + 1
        index_æ–‡ä»¶å¤¹å = columns.index('æ–‡ä»¶å¤¹å') + 1
        index_æ–°æ–‡ä»¶å¤¹ = columns.index('æ–°æ–‡ä»¶å¤¹') + 1
        index_å›¾ç‰‡è·¯å¾„ = columns.index('å›¾ç‰‡è·¯å¾„') + 1
        
        for row in ws.iter_rows(min_row=2):
            æ–‡ä»¶å = row[index_æ–‡ä»¶å - 1].value
            æ‹“å±•å = row[index_æ‹“å±•å - 1].value
            æ–‡ä»¶å¤¹å = row[index_æ–‡ä»¶å¤¹å - 1].value
            æ–°æ–‡ä»¶å¤¹ = row[index_æ–°æ–‡ä»¶å¤¹ - 1].value
            å›¾ç‰‡è·¯å¾„ = row[index_å›¾ç‰‡è·¯å¾„ - 1].value
            
            # åŸå§‹æ–‡ä»¶å¤¹è·¯å¾„
            if æ–‡ä»¶å¤¹å:
                old_folder = os.path.join(folder_path, sheet, æ–‡ä»¶å¤¹å)
            else:
                old_folder = os.path.join(folder_path, sheet)
            
            # æ–°æ–‡ä»¶å¤¹è·¯å¾„
            if æ–°æ–‡ä»¶å¤¹:
                new_folder = os.path.join(folder_path, sheet, æ–°æ–‡ä»¶å¤¹)
                if not os.path.exists(new_folder):
                    os.makedirs(new_folder)
                
                # ç§»åŠ¨æ¨¡å‹æ–‡ä»¶
                try:
                    old_model_path = os.path.join(old_folder, f"{æ–‡ä»¶å}{æ‹“å±•å}")
                    new_model_path = os.path.join(new_folder, f"{æ–‡ä»¶å}{æ‹“å±•å}")
                    if os.path.exists(old_model_path):
                        os.rename(old_model_path, new_model_path)
                except Exception as e:
                    print(e)
                
                # ç§»åŠ¨å›¾ç‰‡æ–‡ä»¶
                try:
                    old_image_path = os.path.join(old_folder, f"{æ–‡ä»¶å}.png")
                    new_image_path = os.path.join(new_folder, f"{æ–‡ä»¶å}.png")
                    if å›¾ç‰‡è·¯å¾„:
                        if os.path.exists(old_image_path):
                            os.rename(old_image_path, new_image_path)
                except Exception as e:
                    print(e)
                
                # ç§»åŠ¨ JSON æ–‡ä»¶
                try:
                    old_json_path = os.path.join(old_folder, f"{æ–‡ä»¶å}.json")
                    new_json_path = os.path.join(new_folder, f"{æ–‡ä»¶å}.json")
                    if os.path.exists(old_json_path):
                        os.rename(old_json_path, new_json_path)
                except Exception as e:
                    print(e)
                
                row[index_å›¾ç‰‡è·¯å¾„ - 1].value = new_image_path
                row[index_æ–‡ä»¶å¤¹å-1].value = æ–°æ–‡ä»¶å¤¹
                row[index_æ–°æ–‡ä»¶å¤¹-1].value = ''
    
    # ä¿å­˜ä¿®æ”¹åçš„è¡¨æ ¼
    wb.save(excel_path)


def update_model_json(folder_path):
    excel_name = "model_info.xlsx"
    excel_path = os.path.join(folder_path, excel_name)
    wb = load_workbook(excel_path)
    
    json_name = "model_info.json"
    base_json_path = os.path.join(folder_path, json_name)
    
    # è¯»å–ç°æœ‰çš„ model_info.json æ•°æ®
    with open(base_json_path, 'r', encoding='utf-8') as f:
        base_model_info_json = json.load(f)
    
    # éå†å·¥ä½œè¡¨
    for sheet in wb.sheetnames:
        ws = wb[sheet]
        # è·å–è¡¨å¤´ç´¢å¼•æ˜ å°„
        headers = [cell.value for cell in list(ws.iter_rows(min_row=1, max_row=1))[0]]
        header_index = {header: idx - 1 for idx, header in enumerate(headers, start=1)}
        
        for row in ws.iter_rows(min_row=2, values_only=False):
            # è·å–æ–‡ä»¶ååŠæ–‡ä»¶å¤¹ä¿¡æ¯
            file_name = row[0].value  # æ–‡ä»¶å
            if not bool(file_name) :
                continue
            
            #! èµ‹å€¼è¡¨è¾¾å¼
            #index = header_index.get('url')
            #value = row[index].value if index is not None and index < len(row) else ''
            #model_entry['url'] = value or ''
            # ç­‰åŒäº
            # value = row[header_index.get('url')] if header_index.get('url') is not None and header_index.get('url') < len(row) else ''
            # ç­‰åŒäº èµ‹å€¼è¡¨è¾¾å¼ walrus operator :=ï¼Œå®ƒå…è®¸ä½ åœ¨æ¡ä»¶è¡¨è¾¾å¼å†…éƒ¨è¿›è¡Œèµ‹å€¼ã€‚è¿™ç§æ–¹å¼å¯ä»¥åœ¨ä¸€è¡Œä¸­å®Œæˆæ‰€æœ‰æ“ä½œï¼Œä½†æ˜¯å¯èƒ½ä¼šé™ä½ä»£ç çš„å¯è¯»æ€§
            # model_entry['url'] = (row[index].value if (index := header_index.get('url')) is not None and index < len(row) else '') or ''
            
            file_name = (row[index].value if (index := header_index.get('æ–‡ä»¶å')) is not None and index < len(row) else '') or ''  # æ–‡ä»¶å
            file_ext = (row[index].value if (index := header_index.get('æ‹“å±•å')) is not None and index < len(row) else '') or ''  # æ‹“å±•å
            original_name = (row[index].value if (index := header_index.get('åŸå')) is not None and index < len(row) else '') or '' # åŸå
            model_folder = (row[index].value if (index := header_index.get('æ–‡ä»¶å¤¹å')) is not None and index < len(row) else '') or ''  # æ–‡ä»¶å¤¹å
            ç±»å‹ = (row[index].value if (index := header_index.get('ç±»å‹')) is not None and index < len(row) else '') or ''  # ç±»å‹
            é£æ ¼ = (row[index].value if (index := header_index.get('é£æ ¼')) is not None and index < len(row) else '') or ''  # é£æ ¼
            ç”¨é€” = (row[index].value if (index := header_index.get('ç”¨é€”')) is not None and index < len(row) else '') or ''  # ç”¨é€”
            ç‰ˆæœ¬ = (row[index].value if (index := header_index.get('ç‰ˆæœ¬')) is not None and index < len(row) else '') or ''  # ç‰ˆæœ¬
            #url = (row[index].value if (index := header_index.get('url')) is not None and index < len(row) else '') or ''  # url
            index_url = header_index.get('url')
            if index_url is not None and index < len(row):
                if row[index_url].hyperlink:
                    url = row[index_url].hyperlink.target
                else:
                    url = row[index_url].value
            å›¾ç‰‡è·¯å¾„ = (row[index].value if (index := header_index.get('å›¾ç‰‡è·¯å¾„')) is not None and index < len(row) else '') or ''  # å›¾ç‰‡è·¯å¾„
            å›¾ç‰‡é¢„è§ˆ = (row[index].value if (index := header_index.get('å›¾ç‰‡é¢„è§ˆ')) is not None and index < len(row) else '') or ''  # å›¾ç‰‡é¢„è§ˆ
            æè¿° = (row[index].value if (index := header_index.get('æè¿°')) is not None and index < len(row) else '') or ''  # æè¿°
            sd_link = (row[index].value if (index := header_index.get('SD Link')) is not None and index < len(row) else '') or ''  # SD Link
            ç‰¹æŒ‡è¯ = (row[index].value if (index := header_index.get('ç‰¹æŒ‡è¯')) is not None and index < len(row) else '') or ''  # ç‰¹æŒ‡è¯
            ä¸»æè¿°è¯ = (row[index].value if (index := header_index.get('ä¸»æè¿°è¯')) is not None and index < len(row) else '') or ''  # ä¸»æè¿°è¯
            è§¦å‘è¯ = (row[index].value if (index := header_index.get('è§¦å‘è¯')) is not None and index < len(row) else '') or ''  # è§¦å‘è¯
            å¯é€‰å½¢è±¡ = (row[index].value if (index := header_index.get('å¯é€‰å½¢è±¡')) is not None and index < len(row) else '') or ''  # å¯é€‰ç»„åˆ
            å¯é€‰æœè£… = (row[index].value if (index := header_index.get('å¯é€‰æœè£…')) is not None and index < len(row) else '') or ''  # å¯é€‰æœè£…
            notes = (row[index].value if (index := header_index.get('notes')) is not None and index < len(row) else '') or ''  # notes
            é»˜è®¤æƒé‡ = (row[index].value if (index := header_index.get('é»˜è®¤æƒé‡')) is not None and index < len(row) else '') or ''  # é»˜è®¤æƒé‡
            æƒé‡èŒƒå›´ = (row[index].value if (index := header_index.get('æƒé‡èŒƒå›´')) is not None and index < len(row) else '') or ''  # æƒé‡èŒƒå›´
            å¦å®šæç¤ºè¯ = (row[index].value if (index := header_index.get('å¦å®šæç¤ºè¯')) is not None and index < len(row) else '') or ''  # å¦å®šæç¤ºè¯
            hash_value = (row[index].value if (index := header_index.get('hash')) is not None and index < len(row) else '') or ''  # hash
            å–œçˆ± = (row[index].value if (index := header_index.get('å–œçˆ±')) is not None and index < len(row) else '') or ''  # å–œçˆ±
            ä¿®æ”¹æ—¶é—´ = (row[index].value if (index := header_index.get('ä¿®æ”¹æ—¶é—´')) is not None and index < len(row) else '') or ''  # ä¿®æ”¹æ—¶é—´
            
            # è®¡ç®—æ¨¡å‹çš„æ–‡ä»¶å¤¹è·¯å¾„
            model_dir = os.path.join(folder_path, sheet, model_folder) if model_folder else os.path.join(folder_path, sheet)
            # æ¨¡å‹å¯¹åº”çš„jsonè·¯å¾„
            model_json_path = os.path.join(model_dir, f'{file_name}.json')
            # åˆ›å»º model_info.json ä¸­çš„é”®
            model_key = os.path.join(sheet, model_folder, f'{file_name}{file_ext}')
            
            # åˆ›å»ºæ¨¡å‹çš„ JSON æ•°æ®ï¼ˆä»å·¥ä½œè¡¨ä¸­æå–ï¼‰
            model_json_data = {
                "pname": original_name,
                "type": ç±»å‹,
                "sd version": ç±»å‹,
                "é£æ ¼":é£æ ¼,
                "ç”¨é€”":ç”¨é€”,
                "ç‰ˆæœ¬":ç‰ˆæœ¬,
                "url": url,
                "description": æè¿°,
                "SD Link": sd_link,
                "specific_words": ç‰¹æŒ‡è¯,
                "main_words": ä¸»æè¿°è¯,
                "trigger_words": è§¦å‘è¯,
                "activation text": è§¦å‘è¯,
                "å¯é€‰å½¢è±¡":å¯é€‰å½¢è±¡,
                "å¯é€‰æœè£…":å¯é€‰æœè£…,
                "notes": notes,
                "preferred weight": é»˜è®¤æƒé‡,
                "æƒé‡èŒƒå›´":æƒé‡èŒƒå›´,
                "negative text": å¦å®šæç¤ºè¯,
                "hash": hash_value,
                "is_favorite": å–œçˆ±,
                "last_modified": ä¿®æ”¹æ—¶é—´,
            }
            # model_json_data.update(existing_json_data) 
            # å¦‚æœ existing_json_data ä¸­çš„é”®åœ¨ model_json_data ä¸­ä¸å­˜åœ¨ï¼Œé‚£ä¹ˆä¼šç›´æ¥å°†è¯¥é”®å€¼å¯¹æ·»åŠ åˆ° model_json_data ä¸­
            # å¦‚æœ existing_json_data ä¸­çš„é”®åœ¨ model_json_data ä¸­å·²ç»å­˜åœ¨ï¼Œé‚£ä¹ˆä¼šç”¨ existing_json_data ä¸­å¯¹åº”é”®çš„å€¼è¦†ç›– model_json_data ä¸­åŸæ¥çš„å€¼
            # ==========================
            # å¦‚æœ existing_json_data ä¸­çš„é”®åœ¨ model_json_data ä¸­å·²ç»å­˜åœ¨ï¼Œä¸è¿›è¡Œè¦†ç›–model_json_dataï¼›
            # å¦‚æœ existing_json_data ä¸­çš„é”®åœ¨ model_json_data ä¸­ä¸å­˜åœ¨ï¼Œç›´æ¥å°†è¯¥é”®å€¼å¯¹æ·»åŠ åˆ° model_json_data ä¸­
            # è¿™ä»½ä»£ç æ˜¯å°†æ¨¡å‹åŒåçš„jsonå†…å®¹è¿½åŠ åˆ°è¦å†™å…¥model_jsonæ–‡ä»¶ä¸­çš„æ•°æ®
            if os.path.exists(model_json_path):
                with open(model_json_path, 'r', encoding='utf-8') as f:
                    existing_json_data = json.load(f)
                    for key, value in existing_json_data.items():
                        if key not in model_json_data:
                            model_json_data[key] = value
            
            # æ›´æ–° model_info.json æ•°æ®
            base_model_info_json[model_key] = model_json_data
            #single_base_model_info_json = {model_key:model_json_data}
            #base_model_info_json.update(single_base_model_info_json)
            
            """
            {
                "description": "=== ä»CivitaiæŠ“å–çš„æè¿° ===\nI've trained two sets of clothing. The trigger words are as follows\n\ntype A: pantyhose, sweater, jacket\n\ntype B: shirt, skirt, fishnet thighhighs\n\n\nV3.0\n\nThe previous 1.0 version of Marie was really too ugly, so I collected a large amount of new material and made the latest XL version, which took a lot of time... I hope everyone can provide more image feedback to build the SDXL community ecosystem and let more people know the advantages of XL...\n\n\nç°åœ¨ç½‘ä¸Šçš„aiç›ä¸½å®åœ¨æ˜¯å¤ªä¸‘äº†ä¸å¿ç›´è§†ï¼Œå› æ­¤å¸Œæœ›å¤§å®¶ç”¨è¿™ä¸ªæ¨¡å‹åˆ›é€ å‡ºæ›´å¤šå¯çˆ±çš„è¿˜åŸçš„ç›ä¸½ï¼Œæ›´å¤šçš„ä¼˜è´¨è¿”å›¾å°±æ˜¯å¯¹æˆ‘æœ€å¤§çš„æ”¯æŒï¼Œä¹Ÿå¸Œæœ›å’Œæ›´å¤šçš„æœ‹å‹è®¨è®ºå¦‚ä½•ç”Ÿæˆæ›´å¥½çœ‹çš„ç›ä¸½ã€‚å¯ä»¥å…³æ³¨æˆ‘çš„pç«™å’ŒXè´¦å·ï¼Œä»¥åä¼šæœ‰æ›´å¤šçš„å›¾ç‰‡åˆ›ä½œä»¥åŠä¼˜è´¨æ¨¡å‹æ”¾å‡º...",
                "sd version": "Flux",
                "activation text": "marie rose",
                "preferred weight": 0.76,
                "negative text": "Negative prompt\n",
                "notes": "Notes"
            }
            """
            single_model_json_data = {
                "description": æè¿°,
                "sd version": ç±»å‹,
                "activation text": è§¦å‘è¯,
                "preferred weight": é»˜è®¤æƒé‡,
                "negative text": å¦å®šæç¤ºè¯,
                "notes": notes,
            }
            # ä¸ç”±ä»£ç å†™å…¥ï¼Œç”¨æœˆå…‰å®ç›’çš„æ‰¹å¤„ç†
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå…ˆç¡®ä¿æ–‡ä»¶å¤¹å­˜åœ¨
            #if not os.path.exists(model_json_path):
            #    os.makedirs(os.path.dirname(model_json_path), exist_ok=True)
            #with open(model_json_path, 'w', encoding='utf-8') as f:
            #    json.dump(single_model_json_data, f, ensure_ascii=False, indent=4)
            
            """if os.path.exists(model_json_path):
                with open(model_json_path, 'r+', encoding='utf-8') as f:
                    model_data = json.load(f)
                    model_data.update(model_json_data)  # ä½¿ç”¨äº†model_json_dataä¹‹å‰åˆå¹¶æ•°æ®
                    f.seek(0) # å°†æ–‡ä»¶æŒ‡é’ˆç§»å›æ–‡ä»¶å¼€å¤´
                    json.dump(model_data, f, ensure_ascii=False, indent=4) # å†™å…¥æ›´æ–°åçš„ JSON æ•°æ®
            else:
                # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºå¹¶å†™å…¥
                os.makedirs(os.path.dirname(model_json_path), exist_ok=True)
                with open(model_json_path, 'w', encoding='utf-8') as f:
                    json.dump(model_json_data, f, ensure_ascii=False, indent=4)"""
    
    # ä¿å­˜æ›´æ–°åçš„ model_info.json æ–‡ä»¶
    with open(base_json_path, 'w', encoding='utf-8') as f:
        json.dump(base_model_info_json, f, ensure_ascii=False, indent=4)

def format_excel(folder_path):
    excel_name = "model_info.xlsx"
    excel_path = os.path.join(folder_path, excel_name)
    wb = load_workbook(excel_path)
    for sheet in wb.sheetnames:
        ws = wb[sheet]
        rows = list(ws.iter_rows(min_row=2, values_only=True))
        total_rows = len(rows)  
        columns = [cell.value for cell in list(ws.iter_rows(min_row=1, max_row=1))[0]]
        index_æ–‡ä»¶å = columns.index('æ–‡ä»¶å')+1
        index_æ‹“å±•å = columns.index('æ‹“å±•å')+1
        index_åŸå = columns.index('åŸå')+1
        index_æ–‡ä»¶å¤¹å = columns.index('æ–‡ä»¶å¤¹å')+1
        index_æ–°æ–‡ä»¶å¤¹ = columns.index('æ–°æ–‡ä»¶å¤¹')+1
        index_ç±»å‹ = columns.index('ç±»å‹')+1
        index_é£æ ¼ = columns.index('é£æ ¼')+1
        index_ç”¨é€” = columns.index('ç”¨é€”')+1
        index_ç‰ˆæœ¬ = columns.index('ç‰ˆæœ¬')+1
        index_url = columns.index('url')+1
        index_å›¾ç‰‡è·¯å¾„ = columns.index('å›¾ç‰‡è·¯å¾„')+1
        index_å›¾ç‰‡é¢„è§ˆ = columns.index('å›¾ç‰‡é¢„è§ˆ')+1
        index_æè¿° = columns.index('æè¿°')+1
        index_SD_Link = columns.index('SD Link')+1
        index_ç‰¹æŒ‡è¯ = columns.index('ç‰¹æŒ‡è¯')+1
        index_ä¸»æè¿°è¯ = columns.index('ä¸»æè¿°è¯')+1
        index_è§¦å‘è¯ = columns.index('è§¦å‘è¯')+1
        index_å¯é€‰å½¢è±¡ = columns.index('å¯é€‰å½¢è±¡')+1
        index_å¯é€‰æœè£… = columns.index('å¯é€‰æœè£…')+1
        index_notes = columns.index('notes')+1
        index_é»˜è®¤æƒé‡ = columns.index('é»˜è®¤æƒé‡')+1
        index_æƒé‡èŒƒå›´ = columns.index('æƒé‡èŒƒå›´')+1
        index_å¦å®šæç¤ºè¯ = columns.index('å¦å®šæç¤ºè¯')+1
        index_hash = columns.index('hash')+1
        index_å–œçˆ± = columns.index('å–œçˆ±')+1
        index_ä¿®æ”¹æ—¶é—´ = columns.index('ä¿®æ”¹æ—¶é—´')+1
        
        # è®©æ¯ä¸€ä¸ªæ¨¡å‹é»˜è®¤æœ‰ä¸€ä¸ªå›¾ç‰‡è·¯å¾„
        for row in ws.iter_rows(min_row=2):
            æ–‡ä»¶å = row[index_æ–‡ä»¶å - 1].value
            æ–‡ä»¶å¤¹å = row[index_æ–‡ä»¶å¤¹å - 1].value
            # åŸå§‹æ–‡ä»¶å¤¹è·¯å¾„
            if æ–‡ä»¶å¤¹å:
                folder = os.path.join(folder_path, sheet, æ–‡ä»¶å¤¹å)
            else:
                folder = os.path.join(folder_path, sheet)
            image_path = os.path.join(folder, f"{æ–‡ä»¶å}.png")
            row[index_å›¾ç‰‡è·¯å¾„-1].value = image_path
            
        # è®¾ç½®å†»ç»“çª—æ ¼ï¼Œå›ºå®šç¬¬ä¸€è¡Œ
        ws.freeze_panes = ws["A2"]
        ws.row_dimensions[1].height = 14
        for row in range(2, total_rows + 1):
            ws.row_dimensions[row].height = 100
        ws.column_dimensions[get_column_letter(index_æ–‡ä»¶å)].width = 5
        ws.column_dimensions[get_column_letter(index_æ‹“å±•å)].width = 5
        ws.column_dimensions[get_column_letter(index_åŸå)].width = 5
        ws.column_dimensions[get_column_letter(index_æ–‡ä»¶å¤¹å)].width = 5
        ws.column_dimensions[get_column_letter(index_æ–°æ–‡ä»¶å¤¹)].width = 5
        ws.column_dimensions[get_column_letter(index_ç±»å‹)].width = 5
        ws.column_dimensions[get_column_letter(index_é£æ ¼)].width = 5
        ws.column_dimensions[get_column_letter(index_ç”¨é€”)].width = 5
        ws.column_dimensions[get_column_letter(index_ç‰ˆæœ¬)].width = 5
        ws.column_dimensions[get_column_letter(index_url)].width = 3
        ws.column_dimensions[get_column_letter(index_å›¾ç‰‡è·¯å¾„)].width = 3
        ws.column_dimensions[get_column_letter(index_å›¾ç‰‡é¢„è§ˆ)].width = 17
        ws.column_dimensions[get_column_letter(index_æè¿°)].width = 40
        ws.column_dimensions[get_column_letter(index_SD_Link)].width = 8
        ws.column_dimensions[get_column_letter(index_ç‰¹æŒ‡è¯)].width = 8
        ws.column_dimensions[get_column_letter(index_ä¸»æè¿°è¯)].width = 8
        ws.column_dimensions[get_column_letter(index_è§¦å‘è¯)].width = 8
        ws.column_dimensions[get_column_letter(index_å¯é€‰å½¢è±¡)].width = 30
        ws.column_dimensions[get_column_letter(index_å¯é€‰æœè£…)].width = 30
        ws.column_dimensions[get_column_letter(index_notes)].width = 25
        ws.column_dimensions[get_column_letter(index_é»˜è®¤æƒé‡)].width = 4
        ws.column_dimensions[get_column_letter(index_æƒé‡èŒƒå›´)].width = 10
        ws.column_dimensions[get_column_letter(index_å¦å®šæç¤ºè¯)].width = 6
        ws.column_dimensions[get_column_letter(index_hash)].width = 5
        ws.column_dimensions[get_column_letter(index_å–œçˆ±)].width = 6
        ws.column_dimensions[get_column_letter(index_ä¿®æ”¹æ—¶é—´)].width = 14
        # éšè—åˆ—
        ws.column_dimensions[get_column_letter(index_æ‹“å±•å)].hidden = True
        ws.column_dimensions[get_column_letter(index_å›¾ç‰‡è·¯å¾„)].hidden = True
        ws.column_dimensions[get_column_letter(index_hash)].hidden = True
        ws.column_dimensions[get_column_letter(index_ä¿®æ”¹æ—¶é—´)].hidden = True
        for row in ws.iter_rows(min_row=2):
            url_cell = row[index_url-1]
            if url_cell.hyperlink is None:
                url = url_cell.value
                if url:  # ç¡®ä¿å•å…ƒæ ¼å€¼ä¸ä¸ºç©ºæ‰è®¾ç½®è¶…é“¾æ¥
                    # Hyperlink å¯¹è±¡æ–¹å¼: çµæ´»ä½†ç¨å¤æ‚ï¼Œé€‚ç”¨äºæ‰¹é‡è®¾ç½®æˆ–éœ€è¦æ“ä½œé«˜çº§åŠŸèƒ½ï¼ˆå¦‚åŒºåŸŸè¶…é“¾æ¥ï¼‰ã€‚
                    #hyperlink = Hyperlink(ref=url_cell.coordinate, target=url, display='ğŸŒ')
                    #url_cell.hyperlink = hyperlink
                    #url_cell.value = 'ğŸŒ'
                    
                    # ç›´æ¥è®¾ç½®æ–¹å¼ (cell.hyperlink): ç®€æ´æ˜“ç”¨ï¼Œæ¨èç”¨äºå•ä¸ªæˆ–å°‘é‡è¶…é“¾æ¥æ“ä½œ
                    url_cell.hyperlink = url  # ç›´æ¥è®¾ç½®å•å…ƒæ ¼çš„è¶…é“¾æ¥
                    url_cell.style = "Hyperlink"  # è®¾ç½®è¶…é“¾æ¥æ ·å¼
                    url_cell.value = 'ğŸŒğŸŒğŸŒ'
        
        for row in ws.iter_rows(min_row=2):
            è§¦å‘è¯_cell = row[index_è§¦å‘è¯-1]
            ç‰¹æŒ‡è¯_value = row[index_ç‰¹æŒ‡è¯-1].value
            ä¸»æè¿°è¯_value = row[index_ä¸»æè¿°è¯-1].value
            if bool(ç‰¹æŒ‡è¯_value) and bool(ä¸»æè¿°è¯_value):
                è§¦å‘è¯_cell.value = ','.join([ç‰¹æŒ‡è¯_value,ä¸»æè¿°è¯_value])
        
        # è®¾ç½®å•å…ƒæ ¼è‡ªåŠ¨æ¢è¡Œ
        for row in ws.iter_rows(min_row=1):
            for cell in row:
                cell.alignment = Alignment(wrap_text=True, horizontal='left', vertical='center')
    
    sheet_names = ['Stable-diffusion','VAE']
    for sheet_name in sheet_names:
        ws = wb[sheet_name]
        ws.column_dimensions[get_column_letter(index_SD_Link)].hidden = True
        ws.column_dimensions[get_column_letter(index_ç‰¹æŒ‡è¯)].hidden = True
        ws.column_dimensions[get_column_letter(index_ä¸»æè¿°è¯)].hidden = True
        ws.column_dimensions[get_column_letter(index_è§¦å‘è¯)].hidden = True
        ws.column_dimensions[get_column_letter(index_å¯é€‰å½¢è±¡)].hidden = True
        ws.column_dimensions[get_column_letter(index_å¯é€‰æœè£…)].hidden = True
    
    wb.save(excel_path)

def reinsert_image(folder_path):
    excel_name = "model_info.xlsx"
    excel_path = os.path.join(folder_path, excel_name)
    wb = load_workbook(excel_path)
    
    sheets = wb.sheetnames
    # å…ˆéå†æ‰€æœ‰å·¥ä½œè¡¨æ¸…ç©ºå·²æœ‰å›¾ç‰‡
    for sheet in sheets:
        ws = wb[sheet]
        # è·å–å›¾ç‰‡çš„åˆ—è¡¨
        images = list(ws._images)  # åˆ›å»ºä¸€ä¸ªå‰¯æœ¬ä»¥é¿å…åœ¨è¿­ä»£æ—¶ä¿®æ”¹åˆ—è¡¨é•¿åº¦
        for drawing in images:
            ws._images.remove(drawing)
    """# å…ˆéå†æ‰€æœ‰å·¥ä½œè¡¨æ¸…ç©ºå·²æœ‰å›¾ç‰‡ï¼Œè¯¥æ–¹æ³•ä¼šæœ‰æ¦‚ç‡ä¼šé—æ¼åˆ é™¤
    # å¯èƒ½æ˜¯å› ä¸ºåœ¨éå† _images åˆ—è¡¨å¹¶åˆ é™¤å…ƒç´ æ—¶ï¼Œåˆ—è¡¨çš„é•¿åº¦å‘ç”Ÿäº†å˜åŒ–ï¼Œå¯¼è‡´ç´¢å¼•é”™ä¹±ï¼Œä½¿å¾—éƒ¨åˆ†å…ƒç´ æ²¡æœ‰è¢«éå†åˆ°
    for sheet in sheets:
        ws = wb[sheet]
        for drawing in ws._images:
            ws._images.remove(drawing)"""
            
    """# åˆ›å»ºæ–°çš„å·¥ä½œç°¿
    # å¤ªå¤æ‚ï¼Œæ²¡æœ‰é‡‡ç”¨ï¼Œä»£ç æœªå®Œæˆï¼Œä»…å‚è€ƒ
    new_wb = Workbook()
    for sheet_name in wb.sheetnames:
        ws = wb[sheet_name]
        new_ws = new_wb.create_sheet(sheet_name)
        # å¤åˆ¶æ‰€æœ‰æ•°æ®å’Œæ ·å¼
        for row in ws.iter_rows():
            for cell in row:
                new_cell = new_ws[cell.coordinate]
                # å¤åˆ¶å€¼
                new_cell.value = cell.value
                # å¤åˆ¶æ ·å¼
                if cell.has_style:
                # å­—ä½“
                new_cell.font = cell.font
                # è¾¹æ¡†
                new_cell.border = cell.border
                # å¡«å……
                new_cell.fill = cell.fill
                # å¯¹é½æ–¹å¼
                new_cell.alignment = cell.alignment
                # æ•°å­—æ ¼å¼
                new_cell.number_format = cell.number_format
                # ä¿æŠ¤å±æ€§
                new_cell.protection = cell.protection
        # å¤åˆ¶åˆ—å®½
        for col_letter, col_dim in ws.column_dimensions.items():
            new_ws.column_dimensions[col_letter].width = col_dim.width
        # å¤åˆ¶è¡Œé«˜
        for row_num, row_dim in ws.row_dimensions.items():
            new_ws.row_dimensions[row_num].height = row_dim.height
        new_wb = Workbook()
        for sheet_name in wb.sheetnames:
            ws = wb[sheet_name]
            new_ws = new_wb.create_sheet(sheet_name)
            # å¤åˆ¶æ‰€æœ‰æ•°æ®
            for row in ws.iter_rows():
                for cell in row:
                    new_ws[cell.coordinate].value = cell.value
    # åˆ é™¤é»˜è®¤ç”Ÿæˆçš„å·¥ä½œè¡¨ï¼ˆé€šå¸¸åä¸º'Sheet'ï¼‰
    default_sheet_name = 'Sheet'
    for sheet in wb.sheetnames:
        if default_sheet_name in sheet:
            default_sheet = wb[sheet]
            wb.remove(default_sheet)"""
    
    
    for sheet in sheets:
        ws = wb[sheet]
        for row in ws.iter_rows(min_row=2, max_col=12):
            if row[0].value is None :
                break
            for col_index, cell in enumerate(row, start=1):
                value = cell.value
                if value is None or not isinstance(value, str):
                    continue
                if value.startswith('E:\models') and 'png' in value and os.path.exists(value):
                    img = OpenpyxlImage(value)
                    # è°ƒæ•´å•å…ƒæ ¼å®½é«˜
                    img_width = img.width
                    img_height = img.height
                    img_scale = img_width / img_height
                    # å›ºå®šé«˜åº¦å’Œé«˜åº¦éƒ½ä¸º 100 px
                    height_pt = 100  # ç›®æ ‡é«˜åº¦ä¸º 100 px
                    height_px = 100 * (4 / 3)
                    width_ch = height_px / 8
                    
                    # å•å…ƒæ ¼é™åˆ¶ï¼šé«˜åº¦ 133 pxï¼Œå®½åº¦ 133 px
                    # ç­‰åŒäºï¼šè¡Œé«˜ 100 ptï¼Œåˆ—å®½ 16.625 å­—ç¬¦
                    max_height_px = height_px
                    max_width_px = height_px
                    # æ ¹æ®æ¯”ä¾‹è°ƒæ•´å®½åº¦å’Œé«˜åº¦
                    if img_width > max_width_px or img_height > max_height_px:
                        # åˆ¤æ–­ä»¥å“ªä¸ªæ–¹å‘ç¼©æ”¾
                        if img_width / max_width_px > img_height / max_height_px:
                            # æŒ‰å®½åº¦ç¼©æ”¾
                            new_width = max_width_px
                            new_height = int(new_width / img_scale)
                        else:
                            # æŒ‰é«˜åº¦ç¼©æ”¾
                            new_height = max_height_px
                            new_width = int(new_height * img_scale)
                    else:
                        # å›¾ç‰‡å°äºå•å…ƒæ ¼ï¼Œä¿æŒåŸå§‹å¤§å°
                        new_width = img_width
                        new_height = img_height
                    
                    # è®¾ç½®å›¾ç‰‡çš„æ–°å®½åº¦å’Œé«˜åº¦
                    img.width = new_width
                    img.height = new_height
                    
                    colname = get_column_letter(col_index+1)
                    rowindex = cell.row
                    ws.column_dimensions[colname].width = width_ch  # åˆ—å®½å•ä½ä¸ºå­—ç¬¦ï¼Œåƒç´ å•ä½éœ€é™¤ä»¥ 8
                    ws.row_dimensions[rowindex].height = height_pt  # è¡Œé«˜å•ä½ä¸ºç£…ï¼Œåƒç´ å•ä½éœ€é™¤ä»¥ 4/3
                    ws.add_image(img, f"{colname}{rowindex}")
                    print(f'æ’å…¥å›¾ç‰‡: {value} -> å•å…ƒæ ¼ {colname}{rowindex}')
        
        for row in ws.iter_rows(min_row=2, min_col=13):
            if row[0].value is None :
                break
            for col_index, cell in enumerate(row, start=13):
                value = cell.value
                if value is None or not isinstance(value, str):
                    continue
                if value.startswith('D:\AI Tech') and 'png' in value and os.path.exists(value):
                    resized_img_path = value.replace(".png", "_compressed.png")
                    # æ£€æŸ¥å‹ç¼©å›¾ç‰‡è·¯å¾„æ˜¯å¦å­˜åœ¨
                    if not os.path.exists(resized_img_path):
                        try:
                            # å‹ç¼©å›¾ç‰‡
                            max_width = 768
                            max_height = 768
                            # æ‰“å¼€åŸå§‹å›¾ç‰‡
                            img = PILImage.open(value)
                            # è·å–åŸå§‹å›¾ç‰‡çš„å®½é«˜
                            width, height = img.size
                            # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼Œä¿æŒå®½é«˜æ¯”è¿›è¡Œç¼©æ”¾ï¼Œä½¿å›¾ç‰‡æœ€é•¿è¾¹ä¸è¶…è¿‡æŒ‡å®šå€¼
                            ratio = min(max_width / width if width > max_height else 1,
                                        max_height / height if height > max_width else 1)
                            new_width = int(width * ratio)
                            new_height = int(height * ratio)
                            # è¿›è¡Œç¼©æ”¾
                            resized_img = img.resize((new_width, new_height), PILImage.Resampling.LANCZOS)
                            # ä¿å­˜å‹ç¼©åçš„å›¾ç‰‡
                            resized_img.save(resized_img_path)
                        except Exception as e:
                            print(f"å¤„ç†å›¾ç‰‡ {value} æ—¶å‡ºé”™: {e}")
                    
                    img = OpenpyxlImage(resized_img_path)
                    # è°ƒæ•´å•å…ƒæ ¼å®½é«˜
                    img_width = img.width
                    img_height = img.height
                    img_scale = img_width / img_height
                    # å›ºå®šé«˜åº¦å’Œé«˜åº¦éƒ½ä¸º 100 px
                    height_pt = 100  # ç›®æ ‡é«˜åº¦ä¸º 100 px
                    height_px = 100 * (4 / 3)
                    width_ch = height_px / 8
                    
                    # å•å…ƒæ ¼é™åˆ¶ï¼šé«˜åº¦ 133 pxï¼Œå®½åº¦ 133 px
                    # ç­‰åŒäºï¼šè¡Œé«˜ 100 ptï¼Œåˆ—å®½ 16.625 å­—ç¬¦
                    max_height_px = height_px
                    max_width_px = height_px
                    # æ ¹æ®æ¯”ä¾‹è°ƒæ•´å®½åº¦å’Œé«˜åº¦
                    if img_width > max_width_px or img_height > max_height_px:
                        # åˆ¤æ–­ä»¥å“ªä¸ªæ–¹å‘ç¼©æ”¾
                        if img_width / max_width_px > img_height / max_height_px:
                            # æŒ‰å®½åº¦ç¼©æ”¾
                            new_width = max_width_px
                            new_height = int(new_width / img_scale)
                        else:
                            # æŒ‰é«˜åº¦ç¼©æ”¾
                            new_height = max_height_px
                            new_width = int(new_height * img_scale)
                    else:
                        # å›¾ç‰‡å°äºå•å…ƒæ ¼ï¼Œä¿æŒåŸå§‹å¤§å°
                        new_width = img_width
                        new_height = img_height
                    
                    # è®¾ç½®å›¾ç‰‡çš„æ–°å®½åº¦å’Œé«˜åº¦
                    img.width = new_width
                    img.height = new_height
                    
                    ws.column_dimensions[get_column_letter(col_index)].width = 3
                    colname = get_column_letter(col_index+1)
                    rowindex = cell.row
                    ws.column_dimensions[colname].width = width_ch  # åˆ—å®½å•ä½ä¸ºå­—ç¬¦ï¼Œåƒç´ å•ä½éœ€é™¤ä»¥ 8
                    ws.row_dimensions[rowindex].height = height_pt  # è¡Œé«˜å•ä½ä¸ºç£…ï¼Œåƒç´ å•ä½éœ€é™¤ä»¥ 4/3
                    ws.add_image(img, f"{colname}{rowindex}")
                    print(f'æ’å…¥å›¾ç‰‡: {value} -> å•å…ƒæ ¼ {colname}{rowindex}')
    
    wb.save(excel_path)

folder_path = "E:\models"
# JSONå†™å…¥è¡¨æ ¼-OK
json_to_execl(folder_path)

# æ–‡ä»¶é‡å‘½å-OK
rename_filenames(folder_path)

# ç§»åŠ¨æ–‡ä»¶-OK
move_to_newfolder(folder_path)

# æ›´æ–°JSONæ–‡ä»¶-OK
update_model_json(folder_path)

# æ ¼å¼åŒ–è¡¨æ ¼æ ·å¼-OK
format_excel(folder_path)

# é‡æ–°æ’å…¥å›¾ç‰‡-OK
reinsert_image(folder_path)